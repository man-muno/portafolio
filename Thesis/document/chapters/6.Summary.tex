\chapter{Conclusion}
In this last chapter, Rosie is discussed. Some of its advantages, and disadvantages are considered. Furthermore, some next steps for future work are proposed.

%\section{Testing}


\section{System Discussion}

Even though there is extensive research behind smart environments and activity identification, there is limited research regarding securing the home. Therefore, taking the extensive research on another discipline as a starting point is beneficial. Nevertheless, a sizable disadvantage is the considerable amount of research produced by a discipline that is over 60 years old. In consequence, identifying the appropriate applicable techniques to be used, is quite time consuming and resource intensive. 

Furthermore, current research on machine learning algorithms for computer networks rely heavily on standardized training sets. Using the same training sets for comparisons, establishes a baseline against which different machine learning algorithms can be compared. Nevertheless, on their findings many researchers suggest that the datasets needed to be cleaned up, or also processed to extract more features. Unfortunately, not included in the findings are the list of new features, or the resulting dataset after preprocessing. In the context of this research, this is a problem because the type of features that can be extracted from the data provide a lot of information on how their machine learning algorithms work.

From the smart home point of view, the problem is the opposite. There are no standardized or agreed upon training sets for smart home that are publicly available. In my opinion, the root cause of this problem is that technologies and protocols for computer networks are much more standardized than those for smart environments. Second, the topology of computer networks has also been studied much more than sensor topologies for the smart home environment. This results in an easier job at standardization of datasets for the networking context.

From the machine learning point of view, there are some disadvantages from the Rosie system. First, the approach taken by Selim \etAl \cite{hybridMultilevelIntrusion} while developing their hybrid network intrusion detection algorithm is very interesting. They developed a layered architecture for each aspect of the detection process, then implemented seven machine learning algorithms and then tested each one of them with the data for each layer. After testing, they did a complete statistical analysis to decide which algorithm was more suitable for each layer of the architecture. This type of approach to selecting algorithms may be beneficial to Rosie; Testing a wider range of algorithms, and statistically analyzing which ones and under what conditions perform better. 
Another disadvantage of the system, is how the algorithms learn. On one hand, it is not possible to have bulk data to or off-line training. Each user in every house behaves different. On the other hand, it is not possible to train a machine learning algorithm without data. Therefore, there will be a time from the point when the system is started, until the point the algorithm is trained, that no predictions can be achieved. Using on-line learning algorithms may be a way to tackle that problem. However, the compromise is that this approach requires more user, when interacting with notifications about currently sensed events. The policy used by Rosie to counter this problem, is to let the algorithms train for the first week, then predict using the trained model for another week, while at the same time training a second model. After the end of the week, the old model is discarded and swapped for the recently trained one.

During the development of the application domain models, the selected methodology dictates that the analysis objects must be classified into boundary, entity, and control objects. Nevertheless, In the case of these research, the classification of the fixtures was not straightforward. They can be classified as entity objects because their data is the one tracked by the system. However, they also could be classified as boundary objects, because they represent one of the system interfaces with the house´s inhabitants. Users of the system interact directly with the fixtures, even if they do not realize it. The conclusion reached, was to have two types of objects, one representing the data, and the other one describing the interaction element. 

From the architectural point of view, by implementing the blackboard pattern, the system is able to use different knowledge sources that only depend on the blackboard association, and how the tuples are stored and read from the blackboard. This implies that knowledge sources function as independent, self-contained pieces of code. On one hand, this helps localization, and responsibility assignment, but on the other hand allows to add easily new knowledge sources.

Even though the current implementation of Rosie does not implement it, It is possible to create new knowledge sources that communicate with external machine learning systems. For example, it is conceivable to write an expert that takes the data stored on the blackboard and translates it into Python commands. That way deep learning libraries written in other languages, that take advantages of GPUs, can be also used. It is also possible to use web-based machine learning frameworks, to off-load the burden of running those algorithms from what may be the underpowered device that runs Rosie.

By selecting OpenHAB as the execution environment, a couple of compromises must be made. First, when setting up a sensor, OpenHAB allows to define information such as types, and also extra data such as sensor groups. Nevertheless, not all of that information is accessible to the bindings. When the value for one of the items is read from the event bus, the only information available is the name of the item and the new value. This seems like an unnecessary impairment that handicaps the functionality of the bindings. Specially, considering that such meta data may be useful, in particular for automation applications. It is important to note that the meta data is not lost, it is simply not accessible from the event bus. Yet, other interfaces have access to it. However, there are a few of workarounds. The bindings can directly query OpenHAB's own REST interface to access that meta data. However, accessing that meta data through a web interface seems cumbersome and error-prone. \\
Another workaround, the one used by Rosie, is to use the configuration mechanism for the bindings, and write the meta data there as well to be later stored on the binding. The downside from this approach, is that the configuration files have now duplicated information. When the amount of sensors is large, maintaining the configuration files becomes cumbersome.\\
Nevertheless, the advantages of using OpenHAB outweigh this drawback. Having the integration of different home automation systems and technologies, into one single solution, provides Rosie with out-of-the-box extensibility. Furthermore, its message bus architectural style and OSGi container,  enable the implementation of additional components, like the simulator used for testing, that mimic the events of a real home.

Another architectural aspect, is the classification of sensors. Dividing the sensors into motion, presence, environmental, electrical, and point of entry, allow for the experts to request them from to blackboard according to type. That way, the knowledge sources can easily and directly ask for the information that they require. For example, an expert may only query the information from the presence data and the motion data, to correlate it without needing to explicitly know all the names of all the available motion of presence sensors.\\
Furthermore, this classification allows Rosie´s experts to be resilient to data loss or sensor failure. When a sensors comes off-line, the hypotheses may not be reached, but the overall functionality of the system will continue to operate.\\
Having this classification, also allows for more specific data experts to be written. An expert could be developed with some basic rules that characterize normal interactions between the sensors. Not to be used for detection of anomalies, but to be used as classifiers that can  pre-classify data to later be fed to the machine learning algorithms. This would reduce the amount of interaction that the user has with the system for on-line machine learning algorithms.\\
Furthermore, the separation of responsibilities from the current architecture, allows new data extractions experts to be written, that work at the same time with the existing ones. Enabling exploration of new contexts to find different, or even better, features to be extracted. 

In my opinion, the advantages turn Rosie into a platform for developing, deploying, and testing machine learning algorithms on smart environments.

\section{Future Work}
Both the advantages and disadvantages described in the last section provide opportunities to build upon the work presented in this thesis, and expand the research on the smart home environments.
From this perspective, one of the identified opportunities is to build better simulations tools. It is difficult for universities to model the behavior of occupants of a home, without building houses and asking researchers to move into them. By having simulations tools, that also connect easily to frameworks like OpenHAB, research will benefit from being able to test multiple algorithms, in multiple models of homes, with different types of occupants and lifestyles, without the need to build multiple houses. Furthermore, with simulation software it is possible to make the passage of time go faster. Training of machine learning algorithms would go rapidly, to later be tested even on real-world 
scenarios.

The advantage in developing Rosie is the ease of use when testing automation algorithms on the smart home environment. Using this advantage, developing new machine learning algorithms for the context of smart environments would make development more swift.
From the machine learning perspective, it would be very interesting to develop a new set of features, maybe even based on another discipline, and using Rosie as a test platform for analysis. \\
Also interesting would be connecting Rosie to another web-based system. First, having the power of a data center behind Rosie enables the prospect of using more powerful but also more resource-intensive algorithms. Furthermore, the question of what would happen if Rosie is installed in more than one home is also interesting. If all the houses on a block are equipped with Rosie, they could coordinate the threat level between them, making not only one home safer, but the entire neighborhood.

